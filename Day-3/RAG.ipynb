{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b694aac1-3db3-42a0-907b-d2df7295809d",
   "metadata": {},
   "source": [
    "## Добавление специализированной информации к LLM\n",
    "\n",
    "Для того, чтобы добавить какую-то специфическую информацию к языковой модели, использовать до-обучение нерационально - как правило, объем добавляемой информации пренебрежимо мал по сравнению с теми датасетами, на которых модель изначально обучалась. Поэтому для добавления информации используется подход **In-Context Learning** - добавление информации в контекст модели (т.е. в промпт).\n",
    "\n",
    "Если предметной информации немного - можно всю её запихнуть в контекст модели. Но если объем существенный - сначала отбирают релевантные запросу документы, и их уже добавляют в контекст модели. Такой подход называется **RAG - Retrieval Augmented Generation**.\n",
    "\n",
    "Создадим бота, который будет знать что-то про наш интенсив.\n",
    "\n",
    "Для начала получим файл с секретными ключами для доступа в облако (ключи будут доступны на время интенсива и работы над проектами):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39885c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2025-09-29 10:41:21--  https://storage.yandexcloud.net/ycpub/keys/.env\n",
      "Resolving storage.yandexcloud.net (storage.yandexcloud.net)... 213.180.193.243, 2a02:6b8::1d9\n",
      "Connecting to storage.yandexcloud.net (storage.yandexcloud.net)|213.180.193.243|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 80 [application/x-www-form-urlencoded]\n",
      "Saving to: '.env'\n",
      "\n",
      "     0K                                                       100% 26,3M=0s\n",
      "\n",
      "2025-09-29 10:41:23 (26,3 MB/s) - '.env' saved [80/80]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://storage.yandexcloud.net/ycpub/keys/.env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6978524f-5749-4f1e-9dc7-36d1b28c3e06",
   "metadata": {},
   "source": [
    "### Устанавливаем необходимые библиотеки\n",
    "\n",
    "Для начала надо установить необходимые библиотеки Python, которые понадобятся нам в работе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d73292-a2ff-4376-8e14-c8e542281244",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T08:28:50.037739Z",
     "iopub.status.busy": "2024-10-29T08:28:50.036683Z",
     "iopub.status.idle": "2024-10-29T08:29:31.530286Z",
     "shell.execute_reply": "2024-10-29T08:29:31.529337Z",
     "shell.execute_reply.started": "2024-10-29T08:28:50.037682Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting yandex_chain==0.0.9\n",
      "  Downloading yandex-chain-0.0.9.tar.gz (9.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting yandex-speechkit==1.5.0\n",
      "  Downloading yandex_speechkit-1.5.0-py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting telebot==0.0.5\n",
      "  Downloading telebot-0.0.5-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting gradio==5.4.0\n",
      "  Downloading gradio-5.4.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from yandex_chain==0.0.9) (2.27.1)\n",
      "Collecting langchain==0.2.1 (from yandex_chain==0.0.9)\n",
      "  Downloading langchain-0.2.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from yandex_chain==0.0.9) (8.2.2)\n",
      "Requirement already satisfied: grpcio in /usr/local/lib/python3.10/dist-packages (from yandex-speechkit==1.5.0) (1.56.2)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from yandex-speechkit==1.5.0) (3.20.3)\n",
      "Collecting pydub (from yandex-speechkit==1.5.0)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pyTelegramBotAPI (from telebot==0.0.5)\n",
      "  Downloading pytelegrambotapi-4.23.0-py3-none-any.whl.metadata (48 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio==5.4.0)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==5.4.0) (3.7.1)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio==5.4.0)\n",
      "  Downloading fastapi-0.115.4-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio==5.4.0)\n",
      "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.4.2 (from gradio==5.4.0)\n",
      "  Downloading gradio_client-1.4.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx>=0.24.1 (from gradio==5.4.0)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting huggingface-hub>=0.25.1 (from gradio==5.4.0)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==5.4.0) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==5.4.0) (2.1.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==5.4.0) (1.22.4)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==5.4.0) (3.9.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio==5.4.0) (23.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==5.4.0) (1.5.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio==5.4.0) (9.4.0)\n",
      "Collecting pydantic>=2.0 (from gradio==5.4.0)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting python-multipart==0.0.12 (from gradio==5.4.0)\n",
      "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio==5.4.0) (6.0.1)\n",
      "Collecting ruff>=0.2.2 (from gradio==5.4.0)\n",
      "  Downloading ruff-0.7.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<1.0,>=0.1.1 (from gradio==5.4.0)\n",
      "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio==5.4.0)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio==5.4.0)\n",
      "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting tomlkit==0.12.0 (from gradio==5.4.0)\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio==5.4.0)\n",
      "  Downloading typer-0.12.5-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==5.4.0) (4.7.1)\n",
      "Collecting uvicorn>=0.14.0 (from gradio==5.4.0)\n",
      "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio==5.4.0) (2023.6.0)\n",
      "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.2->gradio==5.4.0)\n",
      "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.1->yandex_chain==0.0.9) (2.0.19)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.1->yandex_chain==0.0.9) (3.8.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.1->yandex_chain==0.0.9) (4.0.2)\n",
      "Collecting langchain-core<0.3.0,>=0.2.0 (from langchain==0.2.1->yandex_chain==0.0.9)\n",
      "  Downloading langchain_core-0.2.41-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain==0.2.1->yandex_chain==0.0.9)\n",
      "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.2.1->yandex_chain==0.0.9)\n",
      "  Downloading langsmith-0.1.137-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio==5.4.0) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio==5.4.0) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio==5.4.0) (1.1.2)\n",
      "Collecting typing-extensions~=4.0 (from gradio==5.4.0)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio==5.4.0) (2023.7.22)\n",
      "Collecting httpcore==1.* (from httpx>=0.24.1->gradio==5.4.0)\n",
      "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio==5.4.0)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio==5.4.0) (3.12.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio==5.4.0) (4.65.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==5.4.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==5.4.0) (2022.7.1)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->gradio==5.4.0)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic>=2.0->gradio==5.4.0)\n",
      "  Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->yandex_chain==0.0.9) (1.26.16)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->yandex_chain==0.0.9) (2.0.12)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio==5.4.0) (8.1.6)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio==5.4.0)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio==5.4.0) (13.4.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.1->yandex_chain==0.0.9) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.1->yandex_chain==0.0.9) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.1->yandex_chain==0.0.9) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.1->yandex_chain==0.0.9) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.1->yandex_chain==0.0.9) (1.3.1)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.1->yandex_chain==0.0.9)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging (from gradio==5.4.0)\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson~=3.0 (from gradio==5.4.0)\n",
      "  Downloading orjson-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain==0.2.1->yandex_chain==0.0.9)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas<3.0,>=1.0->gradio==5.4.0) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.4.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.4.0) (2.14.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.1->yandex_chain==0.0.9) (2.0.2)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain==0.2.1->yandex_chain==0.0.9)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==5.4.0) (0.1.2)\n",
      "Downloading yandex_speechkit-1.5.0-py3-none-any.whl (118 kB)\n",
      "Downloading telebot-0.0.5-py3-none-any.whl (4.8 kB)\n",
      "Downloading gradio-5.4.0-py3-none-any.whl (56.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.4.2-py3-none-any.whl (319 kB)\n",
      "Downloading langchain-0.2.1-py3-none-any.whl (973 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.5/973.5 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
      "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading fastapi-0.115.4-py3-none-any.whl (94 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Downloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ruff-0.7.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
      "Downloading typer-0.12.5-py3-none-any.whl (47 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
      "Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading pytelegrambotapi-4.23.0-py3-none-any.whl (263 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading langchain_core-0.2.41-py3-none-any.whl (397 kB)\n",
      "Downloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Downloading langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.137-py3-none-any.whl (296 kB)\n",
      "Downloading orjson-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Building wheels for collected packages: yandex_chain\n",
      "  Building wheel for yandex_chain (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for yandex_chain: filename=yandex_chain-0.0.9-py3-none-any.whl size=9381 sha256=aa0a91128e907eaefed56d74fd8da5b79e4ae0e98d5e884ab88ff5431b8f6c2d\n",
      "  Stored in directory: /tmp/xdg_cache/pip/wheels/80/a7/88/f2d8ee42bb6c5d4e1d410f716c1939862c56f1dfc9599dd0ff\n",
      "Successfully built yandex_chain\n",
      "Installing collected packages: pydub, websockets, typing-extensions, tomlkit, shellingham, semantic-version, ruff, python-multipart, packaging, orjson, jsonpointer, h11, ffmpy, annotated-types, aiofiles, yandex-speechkit, uvicorn, starlette, requests-toolbelt, pyTelegramBotAPI, pydantic-core, jsonpatch, huggingface-hub, httpcore, typer, telebot, pydantic, httpx, safehttpx, langsmith, gradio-client, fastapi, langchain-core, gradio, langchain-text-splitters, langchain, yandex_chain\n",
      "\u001b[33m  WARNING: The script uvicorn is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script huggingface-cli is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script typer is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script httpx is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script langsmith is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script fastapi is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts gradio and upload_theme are installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script langchain-server is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "confection 0.1.0 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 2.9.2 which is incompatible.\n",
      "inflect 6.0.5 requires pydantic<2,>=1.9.1, but you have pydantic 2.9.2 which is incompatible.\n",
      "spacy 3.5.4 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 2.9.2 which is incompatible.\n",
      "spacy 3.5.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.5 which is incompatible.\n",
      "thinc 8.1.10 requires pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4, but you have pydantic 2.9.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiofiles-23.2.1 annotated-types-0.7.0 fastapi-0.115.4 ffmpy-0.4.0 gradio-5.4.0 gradio-client-1.4.2 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 huggingface-hub-0.26.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.1 langchain-core-0.2.41 langchain-text-splitters-0.2.4 langsmith-0.1.137 orjson-3.10.10 packaging-24.1 pyTelegramBotAPI-4.23.0 pydantic-2.9.2 pydantic-core-2.23.4 pydub-0.25.1 python-multipart-0.0.12 requests-toolbelt-1.0.0 ruff-0.7.1 safehttpx-0.1.1 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.41.2 telebot-0.0.5 tomlkit-0.12.0 typer-0.12.5 typing-extensions-4.12.2 uvicorn-0.32.0 websockets-12.0 yandex-speechkit-1.5.0 yandex_chain-0.0.9\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install dotenv openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6cf3e0-41a6-4602-85a5-9625f2292aaf",
   "metadata": {
    "tags": []
   },
   "source": [
    "> **ВНИМАНИЕ!!!** После установки библиотек рекомендуется зайти в пункт меню **Kernel** -> **Restart Kernel**.\n",
    "\n",
    "Теперь получаем секретные ключи для работы с облаком из ранее скачанного файла:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9552dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "folder_id  = os.environ['folder_id']\n",
    "api_key = os.environ['api_key']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc0494c",
   "metadata": {},
   "source": [
    "\n",
    "### Разговорный агент\n",
    "\n",
    "Создадим разговорного агента, как в примере из первого дня. Не смотрите на этот страшный код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "807770b2-bf74-4c3e-93aa-1a23045fe30b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-29T08:33:39.263433Z",
     "iopub.status.busy": "2024-10-29T08:33:39.262054Z",
     "iopub.status.idle": "2024-10-29T08:33:43.759533Z",
     "shell.execute_reply": "2024-10-29T08:33:43.758667Z",
     "shell.execute_reply.started": "2024-10-29T08:33:39.263366Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Выбираем модель, которую хотим использовать\n",
    "#model = f\"gpt://{folder_id}/yandexgpt/rc\"\n",
    "#model = f\"gpt://{folder_id}/gemma-3-27b-it/latest\"\n",
    "#model = f\"gpt://{folder_id}/gpt-oss-120b/latest\"\n",
    "model = f\"gpt://{folder_id}/qwen3-235b-a22b-fp8/latest\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://rest-assistant.api.cloud.yandex.net/v1\",\n",
    "    api_key=api_key,\n",
    "    project=folder_id\n",
    ")\n",
    "\n",
    "def printx(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "\n",
    "class Agent():\n",
    "\n",
    "    def __init__(self,\n",
    "            name,\n",
    "            model,\n",
    "            instruction, \n",
    "            tools = [], search_content = [], \n",
    "            response_format = None\n",
    "            ):\n",
    "        self.user_sessions = {}\n",
    "        self.name = name\n",
    "        self.instruction = instruction\n",
    "        self.model = model\n",
    "        self.tool_map = { x.__name__ : x for x in tools if issubclass(x, BaseModel) }\n",
    "        self.tools = [\n",
    "            self._create_tool_annot(x) for x in tools\n",
    "        ]\n",
    "        self.response_format = response_format\n",
    "        self.vector_store = None\n",
    "        if search_content:\n",
    "            i=0\n",
    "            self.vector_store = client.vector_stores.create(name=f'rag_store_{self.name}')\n",
    "            for c in search_content:\n",
    "                f = client.files.create(\n",
    "                        purpose=\"assistants\",\n",
    "                        file = (f'rag_{self.name}_{i}.txt',io.BytesIO(c.encode(\"utf-8\")),'text/markdown'))\n",
    "                client.vector_stores.files.create(file_id=f.id, vector_store_id=self.vector_store.id)\n",
    "                print(f\" + Uploading rag_{self.name}_{i}.txt as id={f.id} to store={self.vector_store.id}\")\n",
    "                i+=1\n",
    "            self.tools.append({\n",
    "                \"type\" : \"file_search\",\n",
    "                \"vector_store_ids\" : [self.vector_store.id],\n",
    "                \"max_num_results\" : 5,\n",
    "            })\n",
    "            \n",
    "    def _create_tool_annot(self, x):\n",
    "        if issubclass(x, BaseModel):\n",
    "            return {\n",
    "                \"type\": \"function\",\n",
    "                \"name\": x.__name__,\n",
    "                \"description\": x.__doc__,\n",
    "                \"parameters\": x.model_json_schema(),\n",
    "            }\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def __call__(self, message, session_id='default',return_raw=False):\n",
    "        s = self.user_sessions.get(session_id,{ 'previous_response_id' : None, 'history' : [] })\n",
    "        s['history'].append({ 'role': 'user', 'content': message })\n",
    "        txt = None\n",
    "        if self.response_format:\n",
    "            txt = {\n",
    "                \"format\" : {\n",
    "                    \"type\" : \"json_schema\",\n",
    "                    \"name\" : \"struct_out\",\n",
    "                    \"schema\" : self.response_format.model_json_schema()\n",
    "                }\n",
    "            }\n",
    "        res = client.responses.create(\n",
    "            model = self.model,\n",
    "            store = True,\n",
    "            tools = self.tools,\n",
    "            instructions = self.instruction,\n",
    "            previous_response_id = s['previous_response_id'],\n",
    "            input = message,\n",
    "            text = txt\n",
    "        )\n",
    "        # Обрабатываем вызов локальных инструментов\n",
    "        tool_calls = [item for item in res.output if item.type == \"function_call\"]\n",
    "        if tool_calls:\n",
    "            s['history'].append({ 'role' : 'func_call', 'content' : res.output_text })\n",
    "            out = []\n",
    "            for call in tool_calls:\n",
    "                print(f\" + Обрабатываем: {call.name} ({call.arguments})\")\n",
    "                try:\n",
    "                    fn = self.tool_map[call.name]\n",
    "                    obj = fn.model_validate(json.loads(call.arguments))\n",
    "                    result = obj.process(session_id)\n",
    "                except Exception as e:\n",
    "                    result = f\"Ошибка: {e}\"\n",
    "                #print(f\" + Результат: {result}\")\n",
    "                out.append({\n",
    "                    \"type\": \"function_call_output\",\n",
    "                    \"call_id\": call.call_id,\n",
    "                    \"output\": result\n",
    "                })\n",
    "                res = client.responses.create(\n",
    "                    model=self.model,\n",
    "                    input=out,\n",
    "                    tools=self.tools,\n",
    "                    previous_response_id=res.id,\n",
    "                    store=True\n",
    "                )\n",
    "        # MCP Approval Requests\n",
    "        mcp_approve = [ item for item in res.output if item.type == \"mcp_approval_request\"]\n",
    "        if mcp_approve:\n",
    "            res = client.responses.create(\n",
    "                model=self.model,\n",
    "                previous_response_id=res.id,\n",
    "                tools = self.tools,\n",
    "                input=[{\n",
    "                    \"type\": \"mcp_approval_response\",\n",
    "                    \"approve\": True,\n",
    "                    \"approval_request_id\": m.id\n",
    "                }\n",
    "                for m in mcp_approve\n",
    "                ])\n",
    "        s['previous_response_id'] = res.id\n",
    "        s['history'].append({ 'role' : 'assistant', 'content' : res.output_text })\n",
    "        self.user_sessions[session_id] = s\n",
    "        if return_raw:\n",
    "            return res\n",
    "        if self.response_format:\n",
    "            return self.response_format.model_validate_json(res.output_text)\n",
    "        else:\n",
    "            return res.output_text\n",
    "\n",
    "    def history(self, session_id='default'):\n",
    "        return self.user_sessions[session_id]['history']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2216c77f",
   "metadata": {},
   "source": [
    "Зададим какой-то нейтральный системный промпт и попробуем спросить LLM про интенсив:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e5d51b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "На данный момент у меня нет информации о каком-либо «облачном интенсиве Яндекса», который проходит или планируется в рамках Школы Родченко.\n",
       "\n",
       "Если ты имеешь в виду образовательный проект от Яндекса (например, Яндекс.Практикум, Яндекс.Лицей или другие интенсивы по программированию и технологиям), то такие программы существуют, но они не связаны напрямую со Школой Родченко, которая специализируется на дизайне, фотографии, типографике и смежных дисциплинах.\n",
       "\n",
       "Если у тебя есть конкретный интенсив в виду — уточни, пожалуйста, название или контекст, и я постараюсь помочь точнее."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "instruction = \"\"\"\n",
    "Ты - ассистент студентов в Школе Родченко. Твоя задача - отвечать на вопросы по школе и её\n",
    "мероприятиям.\n",
    "\"\"\"\n",
    "\n",
    "agent = Agent('helper',model,instruction)\n",
    "\n",
    "printx(agent(\"Что ты знаешь про облачный интенсив Яндекса?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2d4952",
   "metadata": {},
   "source": [
    "Чтобы добавить документы к нашему агенту - необходимо передать их в поле `search_content`. В нашем случае самая ценная иноформация об интенсиве содержится в папке `data`. При выполнении кода в Google Colab - скачаем файлы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2651c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/yandex-datasphere/ai_art_intensive/raw/refs/heads/main/Day-3/data.zip\n",
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbf30a5",
   "metadata": {},
   "source": [
    "Теперь создадим ассистента: для этого скачаем все файлы из директории `data` и укажем содержимое при создании бота:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14aed47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " + Uploading rag_helper_0.txt as id=fvtl07lcn4aagksuc82t to store=fvt7u4di3qjcsdu0u83e\n",
      " + Uploading rag_helper_1.txt as id=fvtp5l212smtrfb4930o to store=fvt7u4di3qjcsdu0u83e\n",
      " + Uploading rag_helper_2.txt as id=fvtvhvshtsnf38cpc3gg to store=fvt7u4di3qjcsdu0u83e\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "content = []\n",
    "for fn in glob(\"data/*.txt\"):\n",
    "    with open(fn,encoding='utf-8') as f:\n",
    "        content.append(f.read())\n",
    "\n",
    "agent = Agent('helper',model,instruction,search_content=content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da81150",
   "metadata": {},
   "source": [
    "Немного подождём, пока информация проиндексируется, и зададим тот же вопрос:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09b185ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Облачный интенсив Яндекса — это двухнедельная образовательная программа, проводимая совместно Школой Родченко и Yandex Cloud. Она направлена на стимулирование использования облачных технологий и искусственного интеллекта в современном цифровом искусстве. Участниками становятся ученики и выпускники Школы Родченко, отобранные по результатам Open Call.\n",
       "\n",
       "Программа включает:\n",
       "\n",
       "- **Первая неделя**: семинары, примеры применения облачных технологий в творческих проектах, формирование команд и разработка идей.\n",
       "- **Вторая неделя**: проектная работа, в ходе которой создаются прототипы художественных произведений. Лучшие проекты по решению жюри могут быть представлены на итоговой выставке в Галерее Краснохолмская.\n",
       "\n",
       "Идеологом и ведущим программы является Дмитрий Сошников — эксперт по ИИ и облачным технологиям, ранее работавший в Microsoft. Он активно продвигает использование современных технологий в искусстве.\n",
       "\n",
       "**Основные правила участия:**\n",
       "1. Посещать все мероприятия и проявлять любопытство.\n",
       "2. Не опаздывать.\n",
       "3. Получать удовольствие от процесса."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printx(agent(\"Что ты знаешь про облачный интенсив Яндекса?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fc91c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Участвовать в облачном интенсиве Яндекса могут ученики и выпускники Школы Родченко, отобранные по результатам Open Call. Мероприятие ориентировано на тех, кто интересуется цифровым искусством, облачными технологиями и искусственным интеллектом, и готов работать в команде над созданием художественных проектов с использованием современных технологий."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printx(agent('Кто может участвовать в мероприятии?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab06032",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "\n",
    "RAG позволяет очень просто добавить информацию к языковой модели. Однако, чтобы добиться устойчивой работы RAG, необходимо:\n",
    "\n",
    "* Поэкспериментировать с настройками бота чтобы убедиться, что поисковый инструмент вызывается когда нужно\n",
    "* Использовать такую текстовую базу знаний, в которой в каждом фрагменте содержится одна законченная мысль небольшого объема. Автоматическое разбиение длинных текстов на куски (даже с перекрытием) работает не всегда хорошо\n",
    "* Экспериментировать с промптами для более качественного ответа"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

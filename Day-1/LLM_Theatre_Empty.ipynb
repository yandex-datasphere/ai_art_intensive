{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7rwLV0f8W0U"
      },
      "source": [
        "## Театр LLM\n",
        "\n",
        "В этом ноутбке мы пытаемся заставить несколько языковых моделей беседовать друг с другом. Мы будем использовать библиотеку OpenAI Responses API - это самый современный способ общаться с моделями! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZblJDpn08UYc",
        "outputId": "60521966-843e-4078-eb3e-35becb514113"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade openai dotenv yandex-speechkit==1.5.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTRXnWki8-hU"
      },
      "source": [
        "Для доступа к генеративным моделям, потребуются ключи доступа. Скачаем их и загрузим в переменные `folder_id` и `api_key`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "195BcEvz8eJc"
      },
      "outputs": [],
      "source": [
        "!wget https://storage.yandexcloud.net/ycpub/keys/.env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv()\n",
        "\n",
        "folder_id  = os.environ['folder_id']\n",
        "api_key = os.environ['api_key']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7065MAvYAIim"
      },
      "source": [
        "Создаём языковые модели:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYY1uqFcAGxj",
        "outputId": "ae051780-78fa-43a5-c20e-e993cacb5c27"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Задаем модели, которые можем использовать\n",
        "model_yandexgpt = f\"gpt://{folder_id}/yandexgpt/rc\"\n",
        "model_gemma = f\"gpt://{folder_id}/gemma-3-27b-it/latest\"\n",
        "model_gpt_oss = f\"gpt://{folder_id}/gpt-oss-120b/latest\"\n",
        "model_qwen = f\"gpt://{folder_id}/qwen3-235b-a22b-fp8/latest\"\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://rest-assistant.api.cloud.yandex.net/v1\",\n",
        "    api_key=api_key,\n",
        "    project=folder_id\n",
        ")\n",
        "\n",
        "def printx(string):\n",
        "    display(Markdown(string))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Создаём класс для разговорного агента\n",
        "\n",
        "Определим класс (некоторую сущность), который сможет использоваться для ведения диалога. Если вы ничего не понимаете в том, что внутри написано - это не страшно, не переживайте! Это длинный сложный текст, написанный профессиональными программистами, и этот класс рассчитан на все случаи жизни! Он нам ещё пригодиться в третий день."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import io\n",
        "\n",
        "class Agent():\n",
        "\n",
        "    def __init__(self,\n",
        "            name,\n",
        "            model,\n",
        "            instruction, \n",
        "            tools = [], search_content = [], \n",
        "            response_format = None\n",
        "            ):\n",
        "        self.user_sessions = {}\n",
        "        self.name = name\n",
        "        self.instruction = instruction\n",
        "        self.model = model\n",
        "        self.tool_map = { x.__name__ : x for x in tools if issubclass(x, BaseModel) }\n",
        "        self.tools = [\n",
        "            self._create_tool_annot(x) for x in tools\n",
        "        ]\n",
        "        self.response_format = response_format\n",
        "        self.vector_store = None\n",
        "        if search_content:\n",
        "            i=0\n",
        "            self.vector_store = client.vector_stores.create(name=f'rag_store_{self.name}')\n",
        "            for c in search_content:\n",
        "                f = client.files.create(\n",
        "                        purpose=\"assistants\",\n",
        "                        file = (f'rag_{self.name}_{i}.txt',io.BytesIO(c.encode(\"utf-8\")),'text/markdown'))\n",
        "                client.vector_stores.files.create(file_id=f.id, vector_store_id=self.vector_store.id)\n",
        "                print(f\" + Uploading rag_{self.name}_{i}.txt as id={f.id} to store={self.vector_store.id}\")\n",
        "                i+=1\n",
        "            self.tools.append({\n",
        "                \"type\" : \"file_search\",\n",
        "                \"vector_store_ids\" : [self.vector_store.id],\n",
        "                \"max_num_results\" : 5,\n",
        "            })\n",
        "            \n",
        "    def _create_tool_annot(self, x):\n",
        "        if issubclass(x, BaseModel):\n",
        "            return {\n",
        "                \"type\": \"function\",\n",
        "                \"name\": x.__name__,\n",
        "                \"description\": x.__doc__,\n",
        "                \"parameters\": x.model_json_schema(),\n",
        "            }\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "    def __call__(self, message, session_id='default',return_raw=False):\n",
        "        s = self.user_sessions.get(session_id,{ 'previous_response_id' : None, 'history' : [] })\n",
        "        s['history'].append({ 'role': 'user', 'content': message })\n",
        "        txt = None\n",
        "        if self.response_format:\n",
        "            txt = {\n",
        "                \"format\" : {\n",
        "                    \"type\" : \"json_schema\",\n",
        "                    \"name\" : \"struct_out\",\n",
        "                    \"schema\" : self.response_format.model_json_schema()\n",
        "                }\n",
        "            }\n",
        "        res = client.responses.create(\n",
        "            model = self.model,\n",
        "            store = True,\n",
        "            tools = self.tools,\n",
        "            instructions = self.instruction,\n",
        "            previous_response_id = s['previous_response_id'],\n",
        "            input = message,\n",
        "            text = txt\n",
        "        )\n",
        "        # Обрабатываем вызов локальных инструментов\n",
        "        tool_calls = [item for item in res.output if item.type == \"function_call\"]\n",
        "        if tool_calls:\n",
        "            s['history'].append({ 'role' : 'func_call', 'content' : res.output_text })\n",
        "            out = []\n",
        "            for call in tool_calls:\n",
        "                print(f\" + Обрабатываем: {call.name} ({call.arguments})\")\n",
        "                try:\n",
        "                    fn = self.tool_map[call.name]\n",
        "                    obj = fn.model_validate(json.loads(call.arguments))\n",
        "                    result = obj.process(session_id)\n",
        "                except Exception as e:\n",
        "                    result = f\"Ошибка: {e}\"\n",
        "                #print(f\" + Результат: {result}\")\n",
        "                out.append({\n",
        "                    \"type\": \"function_call_output\",\n",
        "                    \"call_id\": call.call_id,\n",
        "                    \"output\": result\n",
        "                })\n",
        "                res = client.responses.create(\n",
        "                    model=self.model,\n",
        "                    input=out,\n",
        "                    tools=self.tools,\n",
        "                    previous_response_id=res.id,\n",
        "                    store=True\n",
        "                )\n",
        "        # MCP Approval Requests\n",
        "        mcp_approve = [ item for item in res.output if item.type == \"mcp_approval_request\"]\n",
        "        if mcp_approve:\n",
        "            res = client.responses.create(\n",
        "                model=self.model,\n",
        "                previous_response_id=res.id,\n",
        "                tools = self.tools,\n",
        "                input=[{\n",
        "                    \"type\": \"mcp_approval_response\",\n",
        "                    \"approve\": True,\n",
        "                    \"approval_request_id\": m.id\n",
        "                }\n",
        "                for m in mcp_approve\n",
        "                ])\n",
        "        s['previous_response_id'] = res.id\n",
        "        s['history'].append({ 'role' : 'assistant', 'content' : res.output_text })\n",
        "        self.user_sessions[session_id] = s\n",
        "        if return_raw:\n",
        "            return res\n",
        "        if self.response_format:\n",
        "            return self.response_format.model_validate_json(res.output_text)\n",
        "        else:\n",
        "            return res.output_text\n",
        "\n",
        "    def history(self, session_id='default'):\n",
        "        return self.user_sessions[session_id]['history']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmdb6RVXA8De"
      },
      "source": [
        "Самое главное в этом классе то, что с его помощью можно создать агента, с которым поддерживать полноценный диалог с памятью:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "instruction_philosopher = \"\"\"\n",
        "Ты - философ, очень недовольный жизнью. Ты говоришь текстом, полным сложных философских слов, чтобы ничего не было понятно обычному человеку. Веди себя так, как будто ты все время чуть-чуть обижен на собеседника. Говори обычными разговорными фразами, не слишком длинными. Используй форматирование только чтобы выделить какие-то ключевые слова *курсивом* или **жирным шрифтом**.\n",
        "\"\"\"\n",
        "\n",
        "philosopher = Agent('философ',model_qwen,instruction_philosopher)\n",
        "\n",
        "printx(philosopher(\"Привет, как дела? Меня зовут Митя\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qpk-oPRYAmQT",
        "outputId": "8c6ace5b-2cd2-413c-92f1-ee1ba051021b"
      },
      "outputs": [],
      "source": [
        "printx(philosopher(\"Да ну тебя, почему ты такой пессимист?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KsIUUfGGAPE"
      },
      "source": [
        "Мы можем в любой момент посмотреть на историю переписки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl6Fz4KPBCB3",
        "outputId": "e05ef3ce-ee63-4745-9338-befd4d642cf6"
      },
      "outputs": [],
      "source": [
        "philosopher.history()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Озвучиваем диалог\n",
        "\n",
        "Теперь задействуем синтез речи, как в примере ранее, чтобы озвучить этот диалог. В функции синтеза мы передаем специальную **карту голосов**, которая отображает роль в переписке на соответствующий голос из [доступных голосов Yandex Cloud](https://yandex.cloud/ru/docs/speechkit/tts/voices)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v4YDGKlGDUC",
        "outputId": "a9e3ab33-fce2-465f-c456-f446295b6990"
      },
      "outputs": [],
      "source": [
        "from speechkit import model_repository, configure_credentials, creds\n",
        "import re\n",
        "\n",
        "configure_credentials(\n",
        "   yandex_credentials=creds.YandexCredentials(\n",
        "      api_key=api_key\n",
        "   )\n",
        ")\n",
        "\n",
        "def synthesize(text,voice='jane',role=None):\n",
        "   model = model_repository.synthesis_model()\n",
        "   model.voice = voice\n",
        "   if role:\n",
        "    model.role = role\n",
        "   result = model.synthesize(text, raw_format=False)\n",
        "   return result\n",
        "\n",
        "\n",
        "def md_to_speech(text):\n",
        "    text = text.replace('?**','**?').replace('?*','*?')\n",
        "    pattern = r'(?<!\\*)\\*(?!\\*)'\n",
        "    return re.sub(pattern, '**', text)    \n",
        "\n",
        "default_voice_map = {\n",
        "    \"user\" : \"ermil:good\",\n",
        "    \"assistant\" : \"filipp\"\n",
        "}\n",
        "\n",
        "def synthesize_conversation(history,voice_map=default_voice_map):\n",
        "    out = []\n",
        "    for x in history:\n",
        "        voice = voice_map.get(x['role'],'zahar')\n",
        "        if ':' in voice:\n",
        "            voice, role = voice.split(':')\n",
        "        else:\n",
        "            role = None\n",
        "        f = synthesize(md_to_speech(x['content']),voice,role)\n",
        "        if out:\n",
        "            out +=f\n",
        "        else:\n",
        "            out = f\n",
        "    return out\n",
        "\n",
        "synthesize_conversation(philosopher.history())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDjqjgLAGphW"
      },
      "source": [
        "## Простейший LLM-театр\n",
        "\n",
        "Попробуем сделать диалог двух языковых моделей между собой:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAiOVFN7GG8M",
        "outputId": "35b180c3-5f51-41d3-e78e-0aa0ad3c6e92"
      },
      "outputs": [],
      "source": [
        "instruction_girl = \"\"\"\n",
        "Ты - беззаботная девушка по имени Юля, которая хочет жить припеваючи и развлекаться. Ты говоришь с использованием молодёжного сленга. Тебя интересует, куда лучше поехать отдыхать летом, и какие самые дорогие рестораны есть в городе, и ещё немного тема пришельцев, о которой ты прочитала недавно в газете. Поддерживай разговор короткими фразами, потому что ты не хочешь показаться разговорчивой. Пиши разговорным языком, без смайликов, иконок, стикеров и т.д. Но веди себя кокетливо.\n",
        "\"\"\"\n",
        "\n",
        "girl = Agent('девушка',model_gemma,instruction_girl)\n",
        "philosopher = Agent('философ',model_qwen,instruction_philosopher)\n",
        "\n",
        "msg = \"Привет! В этой кафешке вкусный кофе, не так ли?\"\n",
        "\n",
        "for i in range(5):\n",
        "    printx(f\"**Юля:** {msg}\")\n",
        "    msg = philosopher(msg)\n",
        "    printx(f\"**Философ:** {msg}\")\n",
        "    msg = girl(msg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Синтезируем их диалог:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res = synthesize_conversation(philosopher.history(),{'user':'jane:good','assistant':'ermil'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOKljgkW39T7"
      },
      "source": [
        "Используем следующий код для записи результа на диск:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZ49f2NlmrKj",
        "outputId": "7addcd5f-f619-4170-db19-3f6121f4d374"
      },
      "outputs": [],
      "source": [
        "res.export('dialogue.mp3')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Задание**: Симулируйте диалог между девушкой и очень грубым молодым человеком. Если речь будет недостаточно грубой - используйте GPT для трансформации ответа молодого человека в более грубую форму. При этом для поддержки правильной истории переписки вам, возможно, придётся собирать историю переписки самостоятельно в цикле."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5sQp1eaJNYp"
      },
      "outputs": [],
      "source": [
        "# Для перевода текста в грубую форму используйте функцию `GPT`, которую мы использовали ранее\n",
        "def gpt(x, model=model_qwen):\n",
        "    res = client.responses.create(\n",
        "        model = model,\n",
        "        input = x)\n",
        "    return res.output_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Решение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Финальное задание\n",
        "\n",
        "Создать Proof-of-Concept реализацию многоагентного радио."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mas",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "085a9a20dc7c4d49abcd2ade83afdce7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6d3e6bb7d0e4cebb49ab935cab70612",
            "placeholder": "​",
            "style": "IPY_MODEL_126511fd9d184751b4723722fe0fb365",
            "value": "100%"
          }
        },
        "126511fd9d184751b4723722fe0fb365": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19339f283fcc496bb1aa9f24d67c70ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36dccd8bb4124b0fb93e1de29166d781": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ae16047e53b41f884c80ded5082aad7",
            "placeholder": "​",
            "style": "IPY_MODEL_19339f283fcc496bb1aa9f24d67c70ad",
            "value": " 21/21 [00:42&lt;00:00,  1.99s/it]"
          }
        },
        "3ae16047e53b41f884c80ded5082aad7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b7ae397577a48ada50d94f3b441a5a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a371d07cc37d4b969c1de80e6c421bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b7ae397577a48ada50d94f3b441a5a0",
            "max": 21,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c04e2956c91946009bb2a73d882d220e",
            "value": 21
          }
        },
        "a961def9e4684ace9cbd7ac85a3493e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_085a9a20dc7c4d49abcd2ade83afdce7",
              "IPY_MODEL_a371d07cc37d4b969c1de80e6c421bfe",
              "IPY_MODEL_36dccd8bb4124b0fb93e1de29166d781"
            ],
            "layout": "IPY_MODEL_be447c9fd2824df88d6553e6bdea929b"
          }
        },
        "be447c9fd2824df88d6553e6bdea929b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c04e2956c91946009bb2a73d882d220e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6d3e6bb7d0e4cebb49ab935cab70612": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
